{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[],"authorship_tag":"ABX9TyOj6B/DXBTe8JIuBl6GBBfL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ResNet Paper implementation**"],"metadata":{"id":"8fQbbk8PFpXb"}},{"cell_type":"markdown","source":["\n","\n","*   Paper link : https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf \n","\n"],"metadata":{"id":"pzZSPYNXF1GJ"}},{"cell_type":"code","source":["# import packages\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"akGnzxZoKRlO","executionInfo":{"status":"ok","timestamp":1659435370839,"user_tz":-540,"elapsed":440,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Convolutional Layers"],"metadata":{"id":"1SU0IxTGMmr7"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"lBHPHm9GV2dS","executionInfo":{"status":"ok","timestamp":1659435371319,"user_tz":-540,"elapsed":3,"user":{"displayName":"48","userId":"17678505092892983243"}}},"outputs":[],"source":["def conv1x1(input_channel: int, output_channel: int, stride: int=1, bias=False):\n","  \"\"\"\n","  input_channel : Number of channels in the input image\n","  output_channel : Number of channels in the output, produced by convolution\n","  stride : Stride of the convolution\n","  \"\"\"\n","\n","  return nn.Conv2d(input_channel, output_channel, kernel_size=1, \n","                   stride=stride, bias=bias)\n","\n","def conv3x3(input_channel: int, output_channel: int, stride: int=1, groups: int=1, \n","            dilation: int=1, bias: bool=False):\n","  \"\"\"\n","  input_channel : Number of channels in the input image\n","  output_channel : Number of channels in the output, produced by convolution\n","  stride : Stride of the convolution\n","  groups : Number of blocked connections from input channels to output channels\n","  dilation : Spacing between kernel elements\n","  bias : bias usage(bool)\n","  \"\"\"\n","\n","  return nn.Conv2d(input_channel, output_channel, kernel_size=3, stride=stride, \n","                   padding=dilation, groups=groups, bias=bias, dilation=dilation)"]},{"cell_type":"markdown","source":["# Block"],"metadata":{"id":"MI-h6oOAMt5L"}},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","  expansion = 1\n","\n","  def __init__(self, inplanes, outplanes, stride=1, downsample=None, groups=1,\n","               base_width=64, dilation=1, norm_layer=None):\n","    \"\"\"\n","    inplanes : Input channel size\n","    outplanes : output channel size\n","    \"\"\"\n","\n","    super(BasicBlock, self).__init__()\n","\n","    if norm_layer is None:\n","      norm_layer = nn.BatchNorm2d\n","    if groups != 1 or base_width != 64:\n","      raise ValueError()\n","    if dilation > 1:\n","      raise NotImplementedError()\n","\n","    self.conv1 = conv3x3(inplanes, outplanes, stride)\n","    self.bn1 = norm_layer(outplanes)\n","    self.relu = nn.Relu(inplace=True)\n","\n","    self.conv2 = conv3x3(outplanes, outplanes)\n","    self.bn2 = norm_layer(outplanes)\n","    \n","    self.downsample = downsample\n","    self.stride = stride\n","\n","  def forward(self, x):\n","    identity = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","\n","    if self.downsample is not None:\n","      identity = self.downsample(x)\n","\n","    out += identity\n","    out = self.relu(out)\n","\n","    return out"],"metadata":{"id":"FRgUB_bZLhnV","executionInfo":{"status":"ok","timestamp":1659435371319,"user_tz":-540,"elapsed":2,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class BottleNeck(nn.Module):\n","  expansion = 4\n","\n","  def __init__(self, inplanes, outplanes, stride=1, downsample=None, groups=1,\n","               base_width=64, dilation=1, norm_layer=None):\n","    \"\"\"\n","    inplanes : Input channel size\n","    outplanes : output channel size\n","    \"\"\"\n","\n","    super(BottleNeck, self).__init__()\n","\n","    if norm_layer is None:\n","      norm_layer = nn.BatchNorm2d\n","\n","    width = int(outplanes * (base_width / 64.)) * groups # for wide ResNet\n","\n","    self.conv1 = conv1x1(inplanes, width)\n","    self.bn1 = norm_layer(width)\n","\n","    self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","    self.bn2 = norm_layer(width)\n","    \n","    self.conv3 =  conv1x1(width, outplanes * self.expansion)\n","    self.bn3 = norm_layer(outplanes * self.expansion)\n","    self.relu = nn.Relu(inplace=True)\n","\n","    self.downsample = downsample\n","    self.stride = stride\n","\n","  def forward(self, x):\n","    identity = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.relu(out)\n","\n","    out = self.conv3(out)\n","    out = self.bn3(out)\n","\n","    if self.downsample is not None:\n","      identity = self.downsample\n","\n","    out += identity\n","    out = self. relu(out)\n","\n","    return out"],"metadata":{"id":"1BgYUN7pDk3R","executionInfo":{"status":"ok","timestamp":1659436764508,"user_tz":-540,"elapsed":314,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"flogo4ilqr-t"}},{"cell_type":"code","source":["class ResNet(nn.Module):\n","  def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n","               groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","               norm_layer=None):\n","    super(ResNet, self).__init__()\n","\n","    if norm_layer is None:\n","      norm_layer = nn.BatchNorm2d\n","    self._norm_layer = norm_layer\n","\n","    self.inplanes = 64\n","    self.dilation = 1\n","\n","    if replace_stride_with_dilation is None:\n","      replace_stride_with_dilation = [False, False, False]\n","\n","    if len(replace_stride_with_dilation) != 3:\n","      raise ValueError()\n","\n","    self.groups = groups\n","    self.base_width = width_per_group\n","\n","    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                           bias=False)\n","    self.bn1 = norm_layer(self.inplanes)\n","    self.relu = nn.Relu(inplace=True)\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    self.layer1 = self._make_layer(block, 64, layers[0])\n","    self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                   dilate=replace_stride_with_dilation[0])\n","    self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                   dilate=replace_stride_with_dilation[1])\n","    self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                   dilate=replace_stride_with_dilation[2])\n","    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","        nn.init.constant_ (m.weight, 1)\n","        nn.init.constant_(m.bias, 0)\n","\n","    if zero_init_residual:\n","      for m in self.modules():\n","        if isinstance(m, BottleNeck):\n","          nn.init.constant_(m.bn3.weight, 0)\n","        elif isinstance(m, BasicBlock):\n","          nn.init.constant_(m.bn2.weight, 0)\n","\n","  def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","      \"\"\"\n","      block : type of block\n","      planes : input shape\n","      blocks : size of layer\n","      \"\"\"\n","\n","      norm_layer = self._norm_layer\n","      downsample = None\n","      previous_dilation = self.dilation\n","      if dilate:\n","        self.dilation *= stride\n","        stride = 1\n","\n","      if stride != 1 or self.inplanes != planes * block.expansion:\n","        downsample = nn.Sequential(\n","            conv1x1(self.inplanes, planes * block.expansion, stride),\n","            norm_layer(planes * block.expansion),\n","        )\n","\n","      layers = []\n","\n","      layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                          self.base_width, previous_dilation, norm_layer))\n","      self.inplanes = planes * block.expansion\n","\n","      for _ in range(1, blocks):\n","        layers.append(block(self.inplanes, planes, groups=self.groups,\n","                            base_width=self.base_width, dilation=self.dilation,\n","                            norm_layer=norm_layer))\n","      \n","      return nn.Sequential(*layers)\n","\n","  def _forward_impl(self, x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.maxpool(x)\n","\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","\n","    x = self.avgpool(x)\n","    x = torch.flatten(x, 1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","  def forward(self, x):\n","    return self._forward_impl(x)"],"metadata":{"id":"oALw3MciItOE","executionInfo":{"status":"ok","timestamp":1659445638335,"user_tz":-540,"elapsed":297,"user":{"displayName":"48","userId":"17678505092892983243"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["model = ResNet()"],"metadata":{"id":"GOV1oKzwqwci"},"execution_count":null,"outputs":[]}]}